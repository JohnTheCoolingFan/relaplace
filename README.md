# relaplace

This is a library for a project I've been thinking of doing for a long time, started around when I just entered university. I wanted it to be my first rust project, but it turned out to be a way harder idea than I thought.

## Introduction

In out world, everything is relative. In mathematics, there is such a term as "infinity", maybe you've heard of it. Also, there's "infinitely-<something>" characteristic, which can be associated with infinitely **big** numbers, inifinitely **small** numbers, etc. We can't quite understand the difference between two infinitely big numbers if we're looking from a perspective of zero. But, if we move to a perspective of one of these infinitely big numbers, we may find that they are just 1 unit apart. Or 100. Or that the other is 2 times larger, and if the first's coordinate system is scaled to its opposite value (1 divided by that number), the other number is really just 1 unit away. See how useful perspective change can be? *Sometimes same can be said about real life...*

But we can't have all the relativity information in the world at a time. Well, unless we live in a quantum superposition and all universes where the outcome is that we don't know this information are destroyed. But we don't want to be destroyed, and we do want to not only know, but store that information too! So, the solution is to record relativity information of *some* relations, but not all. Like take this as an example: In front of me I have my monitor, one meter away. Directly to the right of me is also a microphone half a meter away. With this information, you know relation between me and a monitor, and also me and a microphone. But not between monitor and microphone. That would need to be calculated, based on the information I've given. Maybe some of the readers already would shout "graphs!". And to be honest, that wasn't my immediate reaction. We'll talk about this in the technical section (when it appears (when I get to actually making this lib)). For now, there is one more problem to solve.

Our information set is sparse, meaning not all possible kinds of information is available immediately, some needs to be computed. To get the relativity information between two objects, we need to also get relativity information of all objects inbetween, forming a relativity chain. Kind of like a pirate treasure directions. Find a large tree, face the rising sun, walk 2 steps forward, 256 steps to the left... But what if we don't have a complete relativity chain between these two objects? It's a pretty hard problem to come up with a solution to. I do have a technical solution, but I'm not sure which way to put it into fancy words:

1. These groups of objects are infinitely far away so they are not able to sense each other. Making a relativity link between objects from both of them breaks the rules of the universe but is allowed any way, making them not infinitely far away from each other.
2. These groups of objects exist in two separate universes and bridging the gap by making a relativity link means combining these two universes. Worlds collide, please maintain safe speed.
3. These groups of objects are completely lost in space and will only find someone if they are determined enough. One day the god (game engine) will bless them with a new relativity link so that these groups of objects can interact with each other.

Regardless of which you perfer, the gist is this: if two objects don't have a relativity chain between them available, it means they cannot interact in any real-world way, as the distance between them and relative orientation is unknown. Good luck calculating that.

Of course, this is just a computer program, everything exists in the little silicon chips mixed with copper, gold, and many chemicals, we can make them interact in any way we want them to! Although, I doubt there are physics engines that would let you simulate interactions between two objects if they don't know *at least* distance between them.

## Game-related problems

This system has a lot of pitfalls for some kinds of games, but may introduce cool mechanics to others.

First of all, this is definitely much more resource-expensive than regular coordinates in euclidean space. Having to save minimum set of relativity information isn't that bad by itself. But to get relative position and orientation between two objects, you still need to calculate it. And also you would like to cache that, too (planned to be an opt-out part of this library).

On the other hand, if you have a hierarchy of objects (a space ship that is composed of many parts which are objects, for example) then it reduces the needed calculations, in some cases. Move just the parent node, and all its children stay at same relative positions from the parent, but to outsiders (who calculate their relation to these children) they have moved all together with the parent.

For rendering, you need to know position of each object in camera-space. And just like before, you would need to calculate that most of the time. And there may be a nasty edge case, if you want to cut off objects that are outside of camera's field of view. In traditional coordinate systems, you just take the global position and if it's outside certain area - don't render. Well, with relative space you can go along the relativity chain or graph and stop when the next object is outside of the area of view. But from that object, a relation can go back to the camera and into the area of view, which would be wrongly cut off, as no other relation chains lead to it.

And now, comes the reason I myself wanted to make this project: space games. You see, often games rely on floating-point numbers, which do give you better precision than an integer at a part of their range, but this precision changes as you go out from zero. The Dauntless Wolf has made a [good video on youtube](https://youtu.be/U9JkxsvkpLI) exploring that on the Source game engine. With this relative space you can still use floats, but they won't really have to go too far for most of the game's purposes, like rendering and physics. Having the player and whatever you call center of the map/world very far apart is still allowed! And even may be more precise. For example: have a relativity chain going from the "center" to the player, with nodes along it with their information stored in the low enough values that the precision is staying good along the way. Another example: have a n-dimensional grid with nodes denoted by fixed-point numbers (for example, from the crate [`fixed`](https://crates.io/crates/fixed), or just integers). These nodes act as local anchors that still allow you to get global coordinates of objects inside that grid. You may even add higher-order grids where each node denotes an origin of smaller-order grid, which can even be done dynamically at runtime.

But I've steered away from the track a little bit... Yeah, space! You can have it so that each solar system, galaxy, neighborhood and whatnot is an anchor point, allowing navigation between them. And, if you have FTL travel, you can make an FTL malfunction mechanic where the player would be stuck somewhere mid-jump with absolutely no knowledge where exactly he is and what direction he would need to move in. Yes, that doesn't quite make sense considering star-based navigation exists, but the potential is there.

Thank you for reading :)
